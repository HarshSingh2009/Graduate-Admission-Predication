{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOVkWG6x7vyJ"
   },
   "source": [
    "# Graduate Admission Prediction using Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cUTVWN_M7kb5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "S2gS6ODp9DAu",
    "outputId": "17fff550-cb22-4286-b7dd-eeb0400489cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Admission_Predict.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSe2Fl_49LrD",
    "outputId": "14c1658b-4b83-49e3-abcf-600fc27024a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgtxzvJI9mK8"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KYMcxaU92sG"
   },
   "source": [
    "### Seeing for null or duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GpPB9e0h9MeQ",
    "outputId": "5be28f2a-5ebb-4a31-f4d7-9a0f629752f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Serial No.           0\n",
      "GRE Score            0\n",
      "TOEFL Score          0\n",
      "University Rating    0\n",
      "SOP                  0\n",
      "LOR                  0\n",
      "CGPA                 0\n",
      "Research             0\n",
      "Chance of Admit      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum()) # Duplicated values\n",
    "print(df.isnull().sum()) # Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIlyBb3C9a_6",
    "outputId": "fdfb89b0-7021-42a2-b289-c2e22e704763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "en9IIUNz9yUr"
   },
   "source": [
    "### Dropping Non-Important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "10tHF7Ic9kfv"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Serial No.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DV4ndu8198DB",
    "outputId": "4278c141-a527-4f4c-d5da-60704c672479"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlTYi3Bb_Oaz"
   },
   "source": [
    "## Splitting dataset into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QKpgkg-k_N9c"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ObWdDl8x_ekb",
    "outputId": "ca30b286-f3c0-42c5-ebe2-466fa75b00df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cwv0RDgo_fWP",
    "outputId": "3c787c29-e682-4c4b-e27c-bf1516c4758e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WVck3LDB_vtq"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjXr8ElPAPdD",
    "outputId": "7b2e040c-a513-4c8b-84c8-6cd1a28a170d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "i_UXAVKeA0m9",
    "outputId": "5f26f32d-3966-4e11-bf9a-17b6b28eec39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>324</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>299</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>316</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>300</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>305</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "125        300          100                  3  2.0   3.0  8.66         1\n",
       "328        324          112                  4  4.0   3.5  8.77         1\n",
       "339        324          107                  5  3.5   4.0  8.66         1\n",
       "172        322          110                  4  4.0   5.0  9.13         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "347        299           94                  1  1.0   1.0  7.34         0\n",
       "41         316          105                  2  2.5   2.5  8.20         1\n",
       "180        300          104                  3  3.5   3.0  8.16         0\n",
       "132        309          105                  5  3.5   3.5  8.56         0\n",
       "224        305          105                  2  3.0   2.0  8.23         0\n",
       "\n",
       "[80 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcziOe-8A3kk",
    "outputId": "fb5dadf0-41f6-4d02-df1b-009ff2b30c69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93     0.44\n",
       "23     0.95\n",
       "299    0.71\n",
       "13     0.62\n",
       "90     0.64\n",
       "       ... \n",
       "255    0.79\n",
       "72     0.93\n",
       "396    0.84\n",
       "235    0.88\n",
       "37     0.58\n",
       "Name: Chance of Admit , Length: 320, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVYQyLv_ARQb",
    "outputId": "54153620-84a1-4c18-84a4-8461f7a97e85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWexU8GN-jlI"
   },
   "source": [
    "## Min-Max Scaling (data has tight upper and lower bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yLylyQp8-jCl"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_sc = MinMaxScaler()\n",
    "X_train = min_max_sc.fit_transform(X_train)\n",
    "X_test = min_max_sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fh8WumN_Arkr",
    "outputId": "a83c2d92-599e-4b9e-f749-775144cf4858"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22      , 0.17857143, 0.25      , ..., 0.42857143, 0.25      ,\n",
       "        1.        ],\n",
       "       [0.88      , 0.96428571, 1.        , ..., 0.85714286, 0.91911765,\n",
       "        1.        ],\n",
       "       [0.3       , 0.71428571, 0.5       , ..., 0.57142857, 0.53308824,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.70220588,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.74632353,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.22058824,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bDIGVFOBLue"
   },
   "source": [
    "## Building Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "48L2G_4DBJtp"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tv8rDvNJBaoP"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7, activation='relu', input_dim=7))\n",
    "model.add(Dense(49, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1hu-nScChjf",
    "outputId": "45265fbc-f4a7-4178-dfe9-4d40bc2def77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 49)                392       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 498\n",
      "Trainable params: 498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UsmrKwW8Ci43"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odgbtIOGCyef",
    "outputId": "cc44368f-817c-4971-f17c-1abe3337af31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 3ms/step - loss: 0.7922\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5171\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3150\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1680\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0662\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0307\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0295\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0222\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0120\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0101\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0079\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0073\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0068\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0064\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0059\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0057\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0054\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0052\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 129us/step - loss: 0.0040\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 862us/step - loss: 0.0039\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 225us/step - loss: 0.0038\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 0s/step - loss: 0.0038\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 233us/step - loss: 0.0038\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 0s/step - loss: 0.0038\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0038\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 0s/step - loss: 0.0037\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 0s/step - loss: 0.0037\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.0037\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 0s/step - loss: 0.0037\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 55us/step - loss: 0.0037\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhdW9uzmD-ph",
    "outputId": "0609843d-1d69-4ed7-9d03-eba21f76b809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UetQParyEcv7",
    "outputId": "384dc93c-4cda-441c-85f9-15fe27ac683e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score : 0.8095363815002868\n",
      "MSE score : 0.004404935432875959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(f'R2 score : {r2_score(y_test, y_pred)}')\n",
    "print(f'MSE score : {mean_squared_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVwxg32qGd6_"
   },
   "source": [
    "## Visualizing Loss and Accuracy over each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "C5aq4Np6HKmM",
    "outputId": "8e3fa15f-629f-4f60-c9ed-64f764e788ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c8ed30e5c0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hjLdqdxHrPx"
   },
   "source": [
    "## Save and Deploy Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7EGRG7w2HpBx"
   },
   "outputs": [],
   "source": [
    "model.save('GAP_model.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
